# ðŸ¤– Can Large Language Models Understand and Express Human Emotions?

## ðŸŽ¯ Project Goal
This project investigates how different large language models (LLMs) such as GPT-4, Claude, and Gemini respond to emotionally charged human prompts â€” such as encouragement, regret, empathy, or confrontation.

By comparing their outputs across five emotional/attitudinal scenarios, we explore:
- Can LLMs detect and reflect emotional nuance?
- How do they differ in tone, stance, or emotional vocabulary?
- Do they simulate empathy or remain neutral and robotic?

## ðŸ“‚ Structure
- `prompts/`: Contains 5 emotion-driven scenarios
- `results/`: Raw output from GPT-4, Claude, and Gemini
- `analysis/`: Comparative notes, observations, and reflections

## ðŸ§  Questions
- What do their differences reveal about model alignment?
- Is it possible for an AI to express emotion, or merely mimic tone?

This project is part of my independent exploration into AI and human expression.
